{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f0d8c6-c45c-435c-aa20-480ee45c0a8e",
   "metadata": {},
   "source": [
    "# Data Wrangler for Pokemon Identifier Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41e085",
   "metadata": {},
   "source": [
    "Note: Place any additional gathered images into Tmp Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "edc7e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import csv\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image\n",
    "from imutils import paths #used to get the paths of all images in a dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a300452",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e099a",
   "metadata": {},
   "source": [
    "### Global Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "16018296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wether or not to gather images from the web\n",
    "gatherFromWeb = True\n",
    "\n",
    "#number of frames to gather at most from each gif\n",
    "numFramesExtractGif = 0\n",
    "\n",
    "#generation of pokemon to prepare for the final dataset\n",
    "generationsToPrepare = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "#list of URLs for internet sourced images\n",
    "listOfImageURLs = []\n",
    "\n",
    "#percent of images in scraped directory that will be used for training -- from 0 to 1\n",
    "percentToUseForTrain = .9\n",
    "\n",
    "#directory where images will be placed before being processed\n",
    "tempDirectory = '../Tmp/'\n",
    "\n",
    "#directory for image datasets\n",
    "coreImageDir = \"../Datasets/Images/\"\n",
    "\n",
    "#directory where scraped images will be placed\n",
    "gatherDirectory = '../Datasets/Images/Scraped/'\n",
    "\n",
    "#directory for main neural net data \n",
    "mainInfoDirectory = '../Datasets/Main/'\n",
    "\n",
    "DIR_MODE_IMAGES = '../Datasets/Main/Images/'\n",
    "\n",
    "#list of websites to scrape\n",
    "TARGETURLS = ['https://play.pokemonshowdown.com/sprites/']\n",
    "# [\"https://play.pokemonshowdown.com/sprites/\"]\n",
    "\n",
    "REPROCESS_GIFS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382b5b0-bec6-43e5-b421-d0e5a9e520f9",
   "metadata": {},
   "source": [
    "#### Make directories that will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eae9c9e8-846c-4ba5-ba0d-a8604095b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(coreImageDir) is False: \n",
    "    os.mkdir(coreImageDir)\n",
    "    \n",
    "if os.path.isdir(gatherDirectory) is False:\n",
    "    os.mkdir(gatherDirectory)\n",
    "\n",
    "if os.path.isdir(tempDirectory) is False:\n",
    "    os.mkdir(tempDirectory)\n",
    "    \n",
    "if os.path.isdir(mainInfoDirectory) is False:\n",
    "    os.mkdir(mainInfoDirectory)\n",
    "    \n",
    "if os.path.isdir(os.path.join(mainInfoDirectory, 'Images')) is False:\n",
    "    os.mkdir(os.path.join(mainInfoDirectory, 'Images'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d62c1",
   "metadata": {},
   "source": [
    "### Regex Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "be5c6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiledRE_forwardSlash = re.compile(r'/')\n",
    "compiledRE_gif = re.compile(r'.gif$')\n",
    "compiledRE_png = re.compile(r'.png$')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca63a34",
   "metadata": {},
   "source": [
    "### String Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9dc0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFileNameFromPath(path: string, removeExtension: bool):\n",
    "    nameBeginIndex = path.rfind('/')\n",
    "    fullName = path[nameBeginIndex+1:]\n",
    "    if removeExtension:\n",
    "        extensionBeginIndex = fullName.rfind('.')\n",
    "        return fullName[:extensionBeginIndex]\n",
    "    else:\n",
    "        return fullName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade3db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFileNameFromPath(path: string):\n",
    "    nameBeginIndex = path.rfind('/')\n",
    "    return path[:nameBeginIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c3a9745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateScrapedPath(file: string):\n",
    "    pokemonName = compiledData.getProperPokemonName(file)\n",
    "    if pokemonName is not False:\n",
    "        fullPath = os.path.join(gatherDirectory, pokemonName)\n",
    "        return fullPath\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a7f8c",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0d673c23-ff20-4dc0-b2cf-d9c178e7bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWrangler:\n",
    "    completeDataset = '../Datasets/GeneralData/UpdatedCompletePokemonDataset/pokedex_(Update_04.21).csv'\n",
    "    imageWebLocations = [\n",
    "        ''\n",
    "    ]\n",
    "    def __init__(self):\n",
    "        self.uniqueDexIDs = []\n",
    "        self.uniqueDexNames = []\n",
    "        self.pokemonGenerations = []\n",
    "        self.pokeDictionary = {}\n",
    "        self.populateDataFromFile(DataWrangler.completeDataset)\n",
    "    \n",
    "    def populateDataFromFile(self, filePath: string, generations: list=None):\n",
    "        \n",
    "        with open(filePath) as file: \n",
    "            csv_reader = csv.reader(file, delimiter=',')\n",
    "        \n",
    "            firstLine = True\n",
    "            for line in csv_reader:\n",
    "                if firstLine is not True: \n",
    "                    self.uniqueDexIDs.append(line[1])\n",
    "                    self.uniqueDexNames.append(line[2])\n",
    "                    self.pokemonGenerations.append(line[5])\n",
    "                else: \n",
    "                    #figure out what columns in the dataset contain the pokemon name and pokedexID -- TODO \n",
    "                    firstLine = False\n",
    "\n",
    "    #pick the correct pokemon that a given filename should associate with \n",
    "    def getProperPokemonName(self, inString: string): \n",
    "        potentialMatches = []\n",
    "        potentialMatchesIndex = []\n",
    "        searchString = inString.lower()\n",
    "        counter = 0\n",
    "        \n",
    "        for name in self.uniqueDexNames: \n",
    "            currName = name.lower() \n",
    "            if (currName in searchString):\n",
    "                #need to clean up the string and find a way to chop out the name to compare with directly (eternatus has the name natu in it)\n",
    "                potentialMatches.append(currName)\n",
    "                potentialMatchesIndex.append(counter)\n",
    "            counter += 1\n",
    "\n",
    "        #after going through entire pokedex, go through list of potential matches and check which is most appropriate\n",
    "        currBestMatch = None \n",
    "        currBestMatchIndex = None\n",
    "        \n",
    "        for match in potentialMatches:\n",
    "            #if pokemon name is eternatus\n",
    "            #matched list should include 'natu' AND 'eternatus' \n",
    "            #of the potential matches, determine which is the best\n",
    "\n",
    "            #go through entire string and see how many characters of the string that it matches\n",
    "            charCount = 0\n",
    "            searchStringIndex = 0\n",
    "            continueMatch = True\n",
    "\n",
    "            #get start index of the potential pokemon name \n",
    "            try:\n",
    "                searchStringIndex = searchString.find(match)\n",
    "            except:\n",
    "                #string does not contain name, bad match\n",
    "                continueMatch = False\n",
    "            \n",
    "            if continueMatch is True:\n",
    "                for i in range(len(match)):\n",
    "                    if match[i] == searchString[searchStringIndex]:\n",
    "                        charCount += 1\n",
    "                        searchStringIndex += 1\n",
    "\n",
    "                #see if searchString matches the entire length of the potential pokemon name\n",
    "                if ((currBestMatch is None) or ((charCount == len(match)) and (len(match) > len(currBestMatch)))):\n",
    "                    currBestMatch = match\n",
    "        \n",
    "        if currBestMatch is not None: \n",
    "            return currBestMatch\n",
    "        else:\n",
    "            return False\n",
    "        \n",
    "    def getPokemonGeneration(self, pokemonName: string) -> int:\n",
    "        for counter in range(len(self.uniqueDexNames)):\n",
    "            if (pokemonName.lower() == self.uniqueDexNames[counter].lower()):\n",
    "                return int(self.pokemonGenerations[counter])\n",
    "        return False\n",
    "\n",
    "compiledData = DataWrangler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce509d",
   "metadata": {},
   "source": [
    "### Image Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d44ca95b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split a given gif into seperate images -- will return paths to all new files\n",
    "def gifToImages(pathToGif: string, destinationPath: string):\n",
    "\n",
    "    #get number of keyframes of gif\n",
    "    if (os.path.isfile(pathToGif)):\n",
    "        createdFilePaths = []\n",
    "        \n",
    "        with Image.open(pathToGif) as openGif:\n",
    "            numFrames = openGif.n_frames\n",
    "            numToExtract = 0\n",
    "\n",
    "            #check if the number of frames in a given gif is more than the max number defined to get\n",
    "            if numFramesExtractGif != 0 and numFrames > numFramesExtractGif:\n",
    "                numToExtract = numFramesExtractGif\n",
    "            else:\n",
    "                numToExtract = numFrames\n",
    "\n",
    "            framesToGet = np.linspace(0, openGif.n_frames - 1, numToExtract)\n",
    "            isFirstFrame = True\n",
    "            for frameNumber in framesToGet.astype(np.int64):\n",
    "                openGif.seek(frameNumber)\n",
    "                fileName = f'{extractFileNameFromPath(pathToGif, True)}-{frameNumber}.png'\n",
    "                finalFullPath = os.path.join(destinationPath, fileName)\n",
    "                createdFilePaths.append(finalFullPath)\n",
    "                \n",
    "                if isFirstFrame is True: \n",
    "                    palette = openGif.getpalette()\n",
    "                else:\n",
    "                    openGif.putpalette(palette)\n",
    "                \n",
    "                if os.path.isdir(destinationPath) is False:\n",
    "                    os.mkdir(destinationPath)\n",
    "                # openGif.palette.dirty = 1\n",
    "                # openGif.palette.rawmode = \"RGBA\"\n",
    "                openGif.save(finalFullPath)\n",
    "        return createdFilePaths\n",
    "\n",
    "# gifToImages('./Tmp/abomasnow-mega.gif', generateScrapedPath('./Tmp/abomasnow-mega.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b0eb41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply any formatting that is needed for the given image and place into correct directory\n",
    "def processImage(pathToImage: string, isWebPath: bool, overrideDestinationPath: string=None): \n",
    "    destinationPath = None\n",
    "    if overrideDestinationPath is None:\n",
    "        destinationPath = gatherDirectory\n",
    "    else:\n",
    "        destinationPath = overrideDestinationPath\n",
    "\n",
    "    pokemonName = compiledData.getProperPokemonName(pathToImage)\n",
    "    if ((pokemonName is not False) and (tempDirectory in pathToImage) and len(compiledRE_png.findall(pathToImage)) !=0):\n",
    "        #current image is in the temp directory, copy to other directory\n",
    "        labeledDir = os.path.join(destinationPath, pokemonName)\n",
    "\n",
    "        #dont copy if the file is already in the proper compiled directory\n",
    "        if os.path.isdir(labeledDir) is False: \n",
    "            os.mkdir(labeledDir)\n",
    "        shutil.copy2(pathToImage, labeledDir)\n",
    "        #check if image is a gif and convert to a group of images\n",
    "    elif (len(compiledRE_gif.findall(pathToImage)) != 0):\n",
    "        #it is a gif -- if processing image from other dataset (not currently in tmp), shouldnt do extra copy to tmp directory :: TODO: UNLESS EXTRA PROCESSING IS NEEDED (fixing images in some way)\n",
    "        gifCreationDir = None\n",
    "        \n",
    "        createdGifImages = gifToImages(pathToImage, destinationPath)\n",
    "\n",
    "        #will need to process each image just created\n",
    "        for newImages in createdGifImages:\n",
    "            processImage(newImages, False, destinationPath)\n",
    "\n",
    "# processImage('./Datasets/Images/1300-big-front-gifs/001-bulbasaur-s.gif', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56d940",
   "metadata": {},
   "source": [
    "### Web Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ed136790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadImage(imageURL: string):\n",
    "\n",
    "    #create filename for new file - get file name from URL along with parent directory on remote server (combine)\n",
    "    nameBeginIndex = imageURL.rfind('/')\n",
    "    pathWithoutName = imageURL[:nameBeginIndex]\n",
    "    extendedDirIndex = pathWithoutName.rfind('/')\n",
    "    fileName = pathWithoutName[extendedDirIndex+1:] + '--' + imageURL[nameBeginIndex+1:]\n",
    "\n",
    "    fullNewFilePath = os.path.join(tempDirectory, fileName)\n",
    "\n",
    "    if (os.path.isfile(fullNewFilePath) is not True):\n",
    "        #download the file from the remote and place in new path\n",
    "        read = requests.get(imageURL)\n",
    "\n",
    "        with open (fullNewFilePath, 'wb') as f: \n",
    "            f.write(read.content)\n",
    "            f.close()\n",
    "            \n",
    "# downloadImage('https://play.pokemonshowdown.com/sprites/ani-back/ferroseed.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f288c3",
   "metadata": {},
   "source": [
    "### Supporting methods for image search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c806a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursively search through a provided URL to find gifs\n",
    "def browseForImages(currRoot):\n",
    "    global listOfImageURLs\n",
    "    \n",
    "    #avoid april fools day images on pokemon showdown\n",
    "    if \"afd\" not in currRoot:\n",
    "        page = requests.get(currRoot)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "        results = soup.find_all(\"a\", text=compiledRE_forwardSlash)\n",
    "        pngSources = soup.find_all(\"a\", text=compiledRE_png)\n",
    "        gifSources = soup.find_all(\"a\", text=compiledRE_gif)\n",
    "\n",
    "        for image in pngSources: \n",
    "            full = currRoot + image.text\n",
    "            listOfImageURLs.append(full)\n",
    "\n",
    "        for image in gifSources: \n",
    "            full = currRoot + image.text\n",
    "            listOfImageURLs.append(full)\n",
    "\n",
    "        #navigate through all of the possible directories \n",
    "        for each in results: \n",
    "            subURL = currRoot + each.text\n",
    "            browseForImages(subURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860cf1d7",
   "metadata": {},
   "source": [
    "## Gather data from internet resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2308d23",
   "metadata": {},
   "source": [
    "#### Gather image paths into list and then download images as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f3f56a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gatherFromWeb is True:\n",
    "    #gather target URLs for images\n",
    "    for target in TARGETURLS:\n",
    "        browseForImages(target)\n",
    "\n",
    "    #go through and download images as needed\n",
    "    for url in listOfImageURLs: \n",
    "        downloadImage(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff175689",
   "metadata": {},
   "source": [
    "Took 168 minutes to complete -- with processing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906b685",
   "metadata": {},
   "source": [
    "## Sort data gathered into useable dataset for testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchForFiles(currentDir):\n",
    "    if os.path.isdir(currentDir):\n",
    "        nextLevelContents = os.listdir(currentDir)\n",
    "        for content in nextLevelContents:\n",
    "                #go through all contents except for gathered directory \n",
    "                fullPath = os.path.join(currentDir, content)    \n",
    "                searchForFiles(fullPath)   \n",
    "    else:\n",
    "        #this child has to be a file -- copy to core dataset \n",
    "        pokemonName = compiledData.getProperPokemonName(currentDir)\n",
    "        if pokemonName is not False and compiledData.getPokemonGeneration(pokemonName) in generationsToPrepare:\n",
    "            datasetPath = os.path.join(gatherDirectory, pokemonName)\n",
    "            processImage(currentDir, False, datasetPath)\n",
    "searchForFiles(tempDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf5b77-dead-4f5e-8849-057950d229ab",
   "metadata": {},
   "source": [
    "## Verifiy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d296ed3-43d8-468b-a84c-4d99f729b984",
   "metadata": {},
   "source": [
    "## Test Images to ensure proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25711995-3747-4487-abb4-23ff2148aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFile(filePath) -> bool:\n",
    "    if os.path.getsize(filePath) == 0 or os.path.isdir(filePath):\n",
    "        print(file + \" is zero length or is directory, ignoring\")\n",
    "        return False\n",
    "    elif \"afd\" in filePath:\n",
    "        print(file + \" this is garbage file, removing\")\n",
    "        return False\n",
    "    else:\n",
    "        #attempt to open file to confirm that it is a valid file\n",
    "        try:\n",
    "            tmp = Image.open(filePath)\n",
    "            tmp.load()\n",
    "            if tmp.format != 'PNG':\n",
    "                print(file + \" is not correct format, ignoring\")\n",
    "                return False\n",
    "            elif tmp.n_frames > 1:\n",
    "                print(tmp.format)\n",
    "                print(file + \" has more than one frame, ignoring\")\n",
    "                return False\n",
    "            tmp.close()\n",
    "        except:\n",
    "            print(filePath + \" failed to open, ignoring\")\n",
    "            return False\n",
    "\n",
    "        #ensure all images are encoded in the correct format \n",
    "        with open(filePath, 'rb') as imageFile:\n",
    "            if imageFile.read().startswith(b'RIFF'):\n",
    "                print(file + \" isnt right type, ignoring\")\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# testFile('../Datasets/Main/Images/Train/gyarados/pokemon--gyarados.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30acee7d-bc93-450c-8541-4b904d39c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "listOfPokemonDirs = os.listdir(gatherDirectory)\n",
    "# listOfPokemonDirs = os.listdir('../Datasets/Main/Images/Train/')\n",
    "listOfAllImages = list(paths.list_images(coreImageDir))\n",
    "verifiedFiles = []\n",
    "\n",
    "for file in listOfAllImages: \n",
    "    pokemonName =  compiledData.getProperPokemonName(file)\n",
    "    gen = compiledData.getPokemonGeneration(pokemonName)\n",
    "    if gen in generationsToPrepare: \n",
    "        if testFile(file) is True: \n",
    "            verifiedFiles.append(file)\n",
    "\n",
    "#copy verified files to core model directory\n",
    "for file in verifiedFiles: \n",
    "    pokemonName = compiledData.getProperPokemonName(file)\n",
    "    finalPokemonDir = os.path.join(DIR_MODE_IMAGES, pokemonName)\n",
    "    shutil.copy2(file, finalPokemonDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9370040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# for pokemonDir in listOfPokemonDirs:\n",
    "#     #check if the pokemon is in the generation of targeted pokemon \n",
    "#     pokemonName = compiledData.getProperPokemonName(pokemonDir)\n",
    "#     gen = compiledData.getPokemonGeneration(pokemonName)\n",
    "#     if gen in generationsToPrepare:\n",
    "\n",
    "\n",
    "#         #decide if to copy image, then copy if so \n",
    "#         pathPokemonDir = os.path.join(gatherDirectory, pokemonDir)\n",
    "#         # pathPokemonDir = os.path.join(pokemonDir, \n",
    "#         # fileList = os.listdir('../Datasets/Main/Images/Train/gyarados')|\n",
    "#         fileList = os.listdir(pathPokemonDir)\n",
    "#         verifiedList = []\n",
    "        \n",
    "#         for file in fileList: \n",
    "#             fullPath = os.path.join(pathPokemonDir, file)\n",
    "#             # fullPath = os.path.join('../Datasets/Main/Images/Train/gyarados', file)\n",
    "#             if testFile(fullPath) is True:\n",
    "#                 verifiedList.append(file)\n",
    "\n",
    "#         for file in fileList:\n",
    "#             randCounter += 1\n",
    "#             finalPokemonDir = os.path.join(DIR_MODEL_IMAGES, pokemonName)\n",
    "#             currPath = os.path.join(pathPokemonDir, file)\n",
    "#             if os.path.isdir(finalPokemonDir) is False: \n",
    "#                 os.mkdir(finalPokemonDir)\n",
    "#             shutil.copy2(currPath, os.path.join(finalPokemonTrainDir, file))\n",
    "#             os.remove(currPath)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "831b1e12b54c1ff73ac9f45e5c09cfbb42209f7870334bf75877d041a50f3928"
  },
  "kernelspec": {
   "display_name": "Python 3.8 (XPython)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
