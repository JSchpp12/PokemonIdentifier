{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "447a8f8e-2c0f-4045-94bb-f0cc78190bc4",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pokemon Identifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128da341-ac17-492b-a6a8-7c752a21c4bc",
   "metadata": {},
   "source": [
    "This is going to train a pokemon identifier that will be trained on several data sources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce58d0f-7ef5-4ea5-8349-5cae8410c036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import string\n",
    "import datetime\n",
    "import shutil\n",
    "import argparse\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "import tensorflow.keras.preprocessing.image as preprocessing \n",
    "from tensorflow.data import AUTOTUNE\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from tensorflow.keras import regularizers\n",
    "import tensorflow_addons as tfa\n",
    "from imutils import paths #used to get the paths of all images in a dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98a49e0-1bdc-48cb-83f6-1662d8e6d6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "930eccc9-5041-4594-8fe9-cd87b7c896a9",
   "metadata": {},
   "source": [
    "## Global Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5ced3-51dc-4c58-b69e-3a958da42d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "clearLogs = False\n",
    "strNow = datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "ENV = \"ubuntuLocal\"\n",
    "\n",
    "#path to dataset directory\n",
    "ENV_LOG_DIR = f\"../Logs/{ENV}/\"\n",
    "SESSION_LOG_DIR = f\"../Logs/{ENV}/{strNow}/\"\n",
    "CORE_DATASET = '../Datasets/Main/Images/'\n",
    "# SAVE_DIR = os.path.join(SESSION_LOG_DIR, \"Saves\")\n",
    "# CHECKPOINT_DIR = os.path.join(SAVE_DIR, \"Checkpoints\")\n",
    "# FINAL_SAVE_DIR = os.path.join(SAVE_DIR, \"Final\")\n",
    "if os.path.isdir('../Logs') is False:\n",
    "    os.mkdir('../Logs')\n",
    "if os.path.isdir(ENV_LOG_DIR) is False:\n",
    "    os.mkdir(ENV_LOG_DIR)\n",
    "if os.path.isdir(SESSION_LOG_DIR) is False: \n",
    "    os.mkdir(SESSION_LOG_DIR)\n",
    "\n",
    "numCategories = len(os.listdir(CORE_DATASET))\n",
    "\n",
    "#amount of time to allot for training\n",
    "trainTimeLimit = 0\n",
    "\n",
    "#percentage of core dataset to use for training and testing\n",
    "TRAIN_SPLIT = .9 \n",
    "\n",
    "if clearLogs is True and os.path.isdir('../Logs') :\n",
    "    shutil.rmtree('../Logs')\n",
    "    \n",
    "if os.path.isdir(CORE_DATASET) is False:\n",
    "    print('DATASET NOT FOUND') \n",
    "\n",
    "BATCH_SIZE = 500\n",
    "\n",
    "NUM_EPOCHS = 5\n",
    "\n",
    "IMAGE_HEIGHT = 80\n",
    "IMAGE_WIDTH = 80 \n",
    "#normalization value that will be used for color channels\n",
    "IMAGE_NORM_COLOR = 255 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "912e4819",
   "metadata": {},
   "source": [
    "### Data Pipeline Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9791b2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPE_USE_RAND_ZOOM = True\n",
    "PIPE_RAND_ZOOM_AMT = (-0.10, 0.10)\n",
    "PIPE_USE_CACHE = False\n",
    "PIPE_RATIO_TRAIN = 0.90\n",
    "PIPE_RATIO_VALID = 1 - PIPE_RATIO_TRAIN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46228c90",
   "metadata": {},
   "source": [
    "### Training Params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "deecaa09",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_NODES_IN_CONV = [128]\n",
    "NUM_LAYERS_CONV = [4]\n",
    "CONV_KERNEL_SIZE = [(3,3)]\n",
    "REGULARIZER_USE = [True]\n",
    "REGULARIZER_LEARNING_RATE = [float(0.001)]\n",
    "USE_BATCH_NORMS = [True, False, True]\n",
    "DROPOUT_RATE = [0.0, 0.5, 0.5]    #use same number of elements in list for all dropout args\n",
    "DROPOUT_RATE_HIDDEN = [0.0, 0.5, 0.5]\n",
    "SPATIAL_DROPOUT_USE = False\n",
    "SPATIAL_DROPOUT_RATE = 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d687e646-ed68-456f-9e87-336e52c2a3c4",
   "metadata": {},
   "source": [
    "### Take command line arguments if any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1039fe-dee5-424e-b5d2-f09f73ef2807",
   "metadata": {},
   "outputs": [],
   "source": [
    "if (len(sys.argv) > 0):\n",
    "    print(sys.argv)\n",
    "    listArgs = sys.argv\n",
    "    for arg in listArgs: \n",
    "        splitArg = arg.split('=')\n",
    "        if splitArg[0] == \"timeLimit\": \n",
    "            timeSplit = splitArg[1].split('.')\n",
    "            if (len(timeSplit) == 3):\n",
    "                hours = int(timeSplit[0])\n",
    "                minutes = int(timeSplit[1])\n",
    "                seconds = int(timeSplit[2])\n",
    "                trainTimeLimit = (60*60*hours)+(60*minutes)+seconds\n",
    "                print(f'time limit set to- {trainTimeLimit} seconds') \n",
    "        elif splitArg[0] == \"epochs\":\n",
    "            numEpochs = int(splitArg[1])\n",
    "        elif splitArg[0] == \"cache\":\n",
    "            PIPE_USE_CACHE = bool(splitArg[1])\n",
    "            print('Will utilize caching for dataset')\n",
    "        elif splitArg[0] == \"batchNorm\":\n",
    "            USE_BATCH_NORMS = bool(splitArg[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac77d523-75f2-497a-b854-a61fb10d6a18",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfdde576-c031-44aa-8480-73ec05df04f3",
   "metadata": {},
   "source": [
    "### Create Datasets with TF.Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a72f0b37-61c7-4416-8a6f-fe916b7e518d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# #generate training and testing split \n",
    "# i = int(len(imagePaths) * \n",
    "\n",
    "# datasets = [\n",
    "#     (\"training\", trainPaths, TRAIN_DIR),\n",
    "#     (\"validation\", validationPaths, VALIDATION_DIR)\n",
    "# ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0750f99-ed74-4540-84d3-5d0a97b3f166",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadImages(imagePath):\n",
    "    #encode the image\n",
    "    # tf.print(imagePath)\n",
    "    image = tf.io.read_file(imagePath)\n",
    "    image = tf.image.decode_png(image, channels=3)\n",
    "    image = tf.image.resize_with_pad(image, IMAGE_HEIGHT, IMAGE_WIDTH)\n",
    "    image = tf.cast(image, tf.float32)\n",
    "    \n",
    "    #encode the label for the image\n",
    "    labelParts = tf.strings.split(imagePath, os.sep)\n",
    "    oneHot = labelParts[-2] == classNames \n",
    "    return (image, tf.argmax(oneHot))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a4359e-1a51-4402-8200-f74059700096",
   "metadata": {},
   "outputs": [],
   "source": [
    "seqAugment = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Rescaling(scale=1.0/255),\n",
    "    tf.keras.layers.RandomZoom(\n",
    "        height_factor=PIPE_RAND_ZOOM_AMT, #zoom in by random ammount from +20% to +30%\n",
    "        width_factor=PIPE_RAND_ZOOM_AMT, \n",
    "        fill_mode='constant', \n",
    "        fill_value=0)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60b9ed4-1b80-40da-b76a-4d785b64a33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagePaths = list(paths.list_images(CORE_DATASET))\n",
    "random.seed(32)\n",
    "random.shuffle(imagePaths)\n",
    "trainLabels = [p.split(os.path.sep)[-2] for p in imagePaths] #gather labels from dirs \n",
    "classNames = np.array(sorted(trainLabels))\n",
    "classNames = np.unique(classNames)\n",
    "print(len(imagePaths))\n",
    "\n",
    "numTrain = int(len(imagePaths) * PIPE_RATIO_TRAIN)\n",
    "numVal = int(len(imagePaths) * PIPE_RATIO_VALID)\n",
    "\n",
    "#define pipelines \n",
    "#training dataset \n",
    "trainDS = tf.data.Dataset.from_tensor_slices(imagePaths[:numTrain])\n",
    "trainDS = (trainDS\n",
    "           .shuffle(len(imagePaths)) #shuffle all the images \n",
    "           .map(loadImages, num_parallel_calls=AUTOTUNE) #read images from disk \n",
    "           .apply(tf.data.experimental.ignore_errors())\n",
    "           .map(lambda x, y: (seqAugment(x), y), num_parallel_calls=AUTOTUNE)\n",
    "        )\n",
    "\n",
    "if PIPE_USE_CACHE is True: \n",
    "    trainDS = trainDS.cache()\n",
    "trainDS = (trainDS\n",
    "           .batch(BATCH_SIZE) #batch size\n",
    "           .prefetch(AUTOTUNE)\n",
    "          )\n",
    "\n",
    "#validation dataset\n",
    "valDS = tf.data.Dataset.from_tensor_slices(imagePaths[numTrain :])\n",
    "valDS = (valDS\n",
    "         .map(loadImages, num_parallel_calls=AUTOTUNE)\n",
    "         .apply(tf.data.experimental.ignore_errors()))\n",
    "if PIPE_USE_CACHE is True:\n",
    "    valDS = valDS.cache()\n",
    "valDS = (valDS\n",
    "         .batch(BATCH_SIZE)\n",
    "         .prefetch(AUTOTUNE)\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe20c88-a7b8-458a-bc49-0f3f1f976f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # print(trainPaths[15061])\n",
    "# for images, labels in trainDS.take(1):\n",
    "#     for i in range(9):\n",
    "#         ax = plt.subplot(3, 3, i + 1)\n",
    "#         plt.imshow((images[i].numpy()*255).astype(\"uint8\"))\n",
    "#         plt.title(classNames[labels[i]])\n",
    "#         plt.axis(\"off\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5bf412-0e80-4d0b-a25f-a6dc816d6385",
   "metadata": {},
   "source": [
    "### Define Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa604e1-5e18-41be-9bcf-c0eb24a66f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "counter = 0\n",
    "for useBatchNorms in USE_BATCH_NORMS:\n",
    "    for numConvLayers in NUM_LAYERS_CONV:\n",
    "        for convNodes in NUM_NODES_IN_CONV:\n",
    "            for convKernelSize in CONV_KERNEL_SIZE:\n",
    "                for regIndex in range(0, len(REGULARIZER_LEARNING_RATE)):\n",
    "                    for dropIndex in range(0, len(DROPOUT_RATE)):\n",
    "                        counter += 1\n",
    "                        \n",
    "                        local_useReg = False\n",
    "                        if (regIndex is not None and REGULARIZER_LEARNING_RATE[regIndex] > 0.0) and REGULARIZER_LEARNING_RATE[regIndex] is not False:\n",
    "                            local_useReg = True\n",
    "                            \n",
    "                        #check if using dropout\n",
    "                        local_useDropout = False #use dropout on layers other than hidden layer \n",
    "                        local_useDropout_hidden = False #use dropout on hidden layers\n",
    "                        if DROPOUT_RATE[dropIndex] is not None and DROPOUT_RATE[dropIndex] != 0:\n",
    "                            local_useDropout = True\n",
    "                        if DROPOUT_RATE_HIDDEN[dropIndex] is not None and DROPOUT_RATE_HIDDEN[dropIndex] != 0:\n",
    "                            local_useDropout_hidden = True\n",
    "\n",
    "                        #create necessary log directories\n",
    "                        local_usingAnyDropout = False\n",
    "                        if local_useDropout is True or local_useDropout_hidden is True:\n",
    "                            local_usingAnyDropout = True\n",
    "\n",
    "                        local_container_dir = os.path.join(SESSION_LOG_DIR, f\"{counter}.cl{numConvLayers}.cn{convNodes}.ckern{convKernelSize}.bnorm{useBatchNorms}.drop{local_usingAnyDropout}.reg{local_useReg}\")\n",
    "                        local_tensorlogs_dir = os.path.join(local_container_dir, 'fit/')\n",
    "                        local_save_dir = os.path.join(local_container_dir, 'saves/')\n",
    "                        local_checkpoint_dir = os.path.join(local_save_dir, 'checkpoints/')\n",
    "                        local_finalsave_dir = os.path.join(local_save_dir, 'final/')\n",
    "\n",
    "                        if os.path.isdir(local_container_dir) is False: \n",
    "                            os.mkdir(local_container_dir)\n",
    "                        if os.path.isdir(local_tensorlogs_dir) is False: \n",
    "                            os.mkdir(local_tensorlogs_dir)\n",
    "                        if os.path.isdir(local_save_dir) is False:\n",
    "                            os.mkdir(local_save_dir)\n",
    "                        if os.path.isdir(local_checkpoint_dir) is False:\n",
    "                            os.mkdir(local_checkpoint_dir)\n",
    "                        if os.path.isdir(local_finalsave_dir) is False: \n",
    "                            os.mkdir(local_finalsave_dir)\n",
    "\n",
    "                        #write summary to file \n",
    "                        infoFile = os.path.join(local_container_dir, \"into.txt\")\n",
    "                        with open(infoFile, 'w') as file: \n",
    "                            file.write(f\"Number of convolution layers: {numConvLayers} \\r\")\n",
    "                            file.write(f\"Number of nodes per convolution layer: {convNodes} \\r\")\n",
    "                            file.write(f\"Input size expected: {IMAGE_WIDTH}, {IMAGE_HEIGHT}\\r\")\n",
    "                            file.write(f\"Epochs: {NUM_EPOCHS}\\r\")\n",
    "                            file.write(f\"Regularizers in use? {local_useReg}\\r\")\n",
    "                            file.write(f\"Regularizer learning rate: {REGULARIZER_LEARNING_RATE[regIndex]}\\r\")\n",
    "                            file.write(f\"Conv kernel size: {convKernelSize}\\r\")\n",
    "                            file.write(f\"Use Batch Normalization: {useBatchNorms}\\r\")\n",
    "                            file.write(f\"Use Dropout: {local_useDropout}\\r\")\n",
    "                            file.write(f\"Use Dropout on hidden: {local_useDropout_hidden}\\r\")\n",
    "                            if local_useDropout: \n",
    "                                file.write(f\"Dropout rate nonhidden: {DROPOUT_RATE[dropIndex]}\\r\")\n",
    "                            if local_useDropout_hidden:\n",
    "                                file.write(f\"Dropout rate nonhidden: {DROPOUT_RATE_HIDDEN[dropIndex]}\\r\")\n",
    "                            file.close()\n",
    "\n",
    "                        #cleanup from last round \n",
    "                        tf.keras.backend.clear_session()\n",
    "\n",
    "                        #define the model \n",
    "                        model = tf.keras.models.Sequential()\n",
    "                        for i in range(numConvLayers):\n",
    "                            if local_useReg is True:\n",
    "                                model.add(tf.keras.layers.Conv2D(int(convNodes),\n",
    "                                                                    convKernelSize,\n",
    "                                                                    activation='relu',\n",
    "                                                                    kernel_regularizer=regularizers.l2(REGULARIZER_LEARNING_RATE[regIndex])))\n",
    "                            else:\n",
    "                                model.add(tf.keras.layers.Conv2D(int(convNodes), convKernelSize, activation='relu'))\n",
    "\n",
    "                            if useBatchNorms is True:\n",
    "                                model.add(tf.keras.layers.BatchNormalization())\n",
    "\n",
    "                            #add additional properties to conv layers\n",
    "                            model.add(tf.keras.layers.MaxPool2D((2,2)))\n",
    "                            if useBatchNorms is True:\n",
    "                                model.add(tf.keras.layers.BatchNormalization())\n",
    "                            #might not need to use dropout here since we might lose some features \n",
    "                            if local_useDropout:\n",
    "                                model.add(tf.keras.layers.Dropout(DROPOUT_RATE[dropIndex]))\n",
    "\n",
    "                        #flatten out \n",
    "                        model.add(tf.keras.layers.Flatten())\n",
    "                        model.add(tf.keras.layers.Dense(512, activation='relu'))\n",
    "\n",
    "                        if useBatchNorms is True: \n",
    "                            model.add(tf.keras.layers.BatchNormalization())\n",
    "                        if local_useDropout_hidden is True:\n",
    "                            model.add(tf.keras.layers.Dropout(DROPOUT_RATE_HIDDEN[dropIndex]))\n",
    "\n",
    "                        model.add(tf.keras.layers.Dense(len(classNames), activation='softmax'))\n",
    "\n",
    "                        model.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                                optimizer=RMSprop(learning_rate=1e-4),\n",
    "                                metrics=['accuracy'])\n",
    "\n",
    "                        #create callbacks as necessary\n",
    "                        checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=local_checkpoint_dir, \n",
    "                                                                                save_weights_only=True, \n",
    "                                                                                verbose=1)\n",
    "                        tensorboard_callback = tf.keras.callbacks.TensorBoard(log_dir=local_tensorlogs_dir,                        \n",
    "                                                                            histogram_freq=1, \n",
    "                                                                            write_graph=True, \n",
    "                                                                            write_images=False, \n",
    "                                                                            embeddings_freq=1, \n",
    "                                                                            profile_batch='1,5')\n",
    "\n",
    "                        time_stopping_callback = None\n",
    "                        history = None\n",
    "                        try:\n",
    "                            if (trainTimeLimit != 0):\n",
    "                                #shorten the time limit to allow for post training data processing\n",
    "                                trainTimeLimit = trainTimeLimit - (60*5) \n",
    "                                time_stopping_callback = tfa.callbacks.TimeStopping(seconds=trainTimeLimit, verbose=1)\n",
    "                                history = model.fit(trainDS, \n",
    "                                                    epochs=NUM_EPOCHS, \n",
    "                                                    validation_data=valDS,\n",
    "                                                    callbacks=[tensorboard_callback, checkpoint_callback, time_stopping_callback])\n",
    "                            else:\n",
    "                                #no time limit callback\n",
    "                                history = model.fit(trainDS, \n",
    "                                            epochs=NUM_EPOCHS, \n",
    "                                            validation_data=valDS,\n",
    "                                            callbacks=[tensorboard_callback, checkpoint_callback])\n",
    "                        except tf.errors.InvalidArgumentError as tferr:\n",
    "                            print(tferr)\n",
    "                            break\n",
    "\n",
    "\n",
    "                        #save model and record completion in info file\n",
    "                        model.save(local_finalsave_dir)\n",
    "                        with open(infoFile, 'a') as file: \n",
    "                            file.write('Training Complete')\n",
    "                            file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccbc3151-66a9-471e-a20b-fc43140aaf4c",
   "metadata": {},
   "source": [
    "#### Zip Logs For Download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b3ed66-9fdc-4e4e-a535-7d552dc015d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "shutil.make_archive('Logs', 'zip', '../Logs')"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
