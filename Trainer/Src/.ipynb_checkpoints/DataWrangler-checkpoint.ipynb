{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "69f0d8c6-c45c-435c-aa20-480ee45c0a8e",
   "metadata": {},
   "source": [
    "# Data Wrangler for Pokemon Identifier Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd41e085",
   "metadata": {},
   "source": [
    "Note: Place any additional gathered images into Tmp Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edc7e986",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import string\n",
    "import csv\n",
    "import re\n",
    "import requests\n",
    "import shutil\n",
    "import random\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a300452",
   "metadata": {},
   "source": [
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef1e099a",
   "metadata": {},
   "source": [
    "### Global Values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16018296",
   "metadata": {},
   "outputs": [],
   "source": [
    "#wether or not to gather images from the web\n",
    "gatherFromWeb = False\n",
    "\n",
    "#number of frames to gather at most from each gif\n",
    "numFramesExtractGif = 0\n",
    "\n",
    "#generation of pokemon to prepare for the final dataset\n",
    "generationsToPrepare = [1, 2, 3, 4, 5, 6, 7, 8]\n",
    "\n",
    "#list of URLs for internet sourced images\n",
    "listOfImageURLs = []\n",
    "\n",
    "#percent of images in scraped directory that will be used for training -- from 0 to 1\n",
    "percentToUseForTrain = .9\n",
    "\n",
    "#directory where images will be placed before being processed\n",
    "tempDirectory = '../Tmp/'\n",
    "\n",
    "#directory for image datasets\n",
    "coreImageDir = \"../Datasets/Images/\"\n",
    "\n",
    "#directory where scraped images will be placed\n",
    "gatherDirectory = '../Datasets/Images/TmpScraped/'\n",
    "\n",
    "#directory for main neural net data \n",
    "mainInfoDirectory = '../Datasets/Main/'\n",
    "\n",
    "DIR_MODEL_IMAGES = '../Datasets/Main/Images/'\n",
    "\n",
    "#list of websites to scrape\n",
    "TARGETURLS = ['https://play.pokemonshowdown.com/sprites/']\n",
    "# [\"https://play.pokemonshowdown.com/sprites/\"]\n",
    "\n",
    "REPROCESS_GIFS = False\n",
    "PROCESS_TEMP_IMAGES = False\n",
    "INCLUDE_ALT_FORMS = False \n",
    "PREPARE_TEST_DS = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7382b5b0-bec6-43e5-b421-d0e5a9e520f9",
   "metadata": {},
   "source": [
    "#### Make directories that will be needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae9c9e8-846c-4ba5-ba0d-a8604095b4be",
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(coreImageDir) is False: \n",
    "    os.mkdir(coreImageDir)\n",
    "    \n",
    "if os.path.isdir(gatherDirectory) is False:\n",
    "    os.mkdir(gatherDirectory)\n",
    "\n",
    "if os.path.isdir(tempDirectory) is False:\n",
    "    os.mkdir(tempDirectory)\n",
    "    \n",
    "if os.path.isdir(mainInfoDirectory) is False:\n",
    "    os.mkdir(mainInfoDirectory)\n",
    "    \n",
    "if os.path.isdir(os.path.join(mainInfoDirectory, 'Images')) is False:\n",
    "    os.mkdir(os.path.join(mainInfoDirectory, 'Images'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54d62c1",
   "metadata": {},
   "source": [
    "### Regex Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be5c6c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "compiledRE_forwardSlash = re.compile(r'/')\n",
    "compiledRE_gif = re.compile(r'.gif$')\n",
    "compiledRE_png = re.compile(r'.png$')\n",
    "compiledRE_special = re.compile(r\"[!@#$']\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eca63a34",
   "metadata": {},
   "source": [
    "### String Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9dc0679",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractFileNameFromPath(path: string, removeExtension: bool):\n",
    "    nameBeginIndex = path.rfind('/')\n",
    "    fullName = path[nameBeginIndex+1:]\n",
    "    if removeExtension:\n",
    "        extensionBeginIndex = fullName.rfind('.')\n",
    "        return fullName[:extensionBeginIndex]\n",
    "    else:\n",
    "        return fullName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ade3db41",
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeFileNameFromPath(path: string):\n",
    "    nameBeginIndex = path.rfind('/')\n",
    "    return path[:nameBeginIndex]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3a9745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generateScrapedPath(file: string):\n",
    "    pokemonName = compiledData.getProperPokemonName(file)\n",
    "    if pokemonName is not False:\n",
    "        fullPath = os.path.join(gatherDirectory, pokemonName)\n",
    "        return fullPath\n",
    "    return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5a7f8c",
   "metadata": {},
   "source": [
    "### Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d673c23-ff20-4dc0-b2cf-d9c178e7bc9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataWrangler:\n",
    "    completeDatasets = [('../Datasets/GeneralData/TheCompletePokemonDataset/pokemon.csv',32, 30, 39), \n",
    "                        ('../Datasets/GeneralData/UpdatedCompletePokemonDataset/pokedex_(Update_04.21).csv', 1, 2, 5)]\n",
    "    imageWebLocations = [\n",
    "        ''\n",
    "    ]\n",
    "    def __init__(self):\n",
    "        self.uniqueDexIDs = []\n",
    "        self.uniqueDexNames = []\n",
    "        self.pokemonGenerations = []\n",
    "        self.pokeDictionary = {}\n",
    "        for file,col_id,col_name,col_gen in DataWrangler.completeDatasets:\n",
    "            self.populateDataFromFile(file, col_id, col_name, col_gen)\n",
    "    \n",
    "    def populateDataFromFile(self, filePath: string, col_id, col_name, col_gen):\n",
    "        with open(filePath, encoding=\"utf8\") as file: \n",
    "            csv_reader = csv.reader(file, delimiter=',')\n",
    "        \n",
    "            firstLine = True\n",
    "            for line in csv_reader:\n",
    "                if firstLine is not True: \n",
    "                    tempID = int(line[col_id])\n",
    "                    if tempID not in self.uniqueDexIDs:\n",
    "                        #remove trailing . keep from creating directories with trailing .\n",
    "                        cleanName = re.sub(\"[.]\", '', line[col_name])\n",
    "                        self.uniqueDexIDs.append(tempID)\n",
    "                        self.uniqueDexNames.append(cleanName)\n",
    "                        self.pokemonGenerations.append(int(line[col_gen]))\n",
    "                else: \n",
    "                    #figure out what columns in the dataset contain the pokemon name and pokedexID -- TODO \n",
    "                    firstLine = False\n",
    "\n",
    "    #pick the correct pokemon that a given filename should associate with -- linear search, might want to improve in future \n",
    "    def getProperPokemonName(self, inString: string): \n",
    "        potentialMatches = []\n",
    "        potentialMatchesIndex = []\n",
    "        searchString = inString.lower()\n",
    "        counter = 0\n",
    "        \n",
    "        for name in self.uniqueDexNames: \n",
    "            currName = name.lower() \n",
    "            cleanCurrName = re.sub(\"[!@#$'._]\", '', currName)\n",
    "            cleanCurrName = cleanCurrName.replace(\" \", \"\")\n",
    "            cleanPathName = re.sub(\"[!@#$'._]\", '', inString)\n",
    "            cleanPathName = cleanPathName.replace(\" \", \"\")\n",
    "            if (currName in searchString or cleanCurrName in searchString or cleanCurrName in cleanPathName):\n",
    "                #need to clean up the string and find a way to chop out the name to compare with directly (eternatus has the name natu in it)\n",
    "                potentialMatches.append(currName)\n",
    "                potentialMatchesIndex.append(counter)\n",
    "            counter += 1\n",
    "\n",
    "        #after going through entire pokedex, go through list of potential matches and check which is most appropriate\n",
    "        currBestMatch = None \n",
    "        currBestMatchIndex = None\n",
    "        if len(potentialMatches) == 1:\n",
    "            return potentialMatches[0]\n",
    "        else:\n",
    "            for match in potentialMatches:\n",
    "                #if pokemon name is eternatus\n",
    "                #matched list should include 'natu' AND 'eternatus' \n",
    "                #of the potential matches, determine which is the best\n",
    "\n",
    "                #go through entire string and see how many characters of the string that it matches\n",
    "                charCount = 0\n",
    "                searchStringIndex = 0\n",
    "                continueMatch = True\n",
    "\n",
    "                #get start index of the potential pokemon name \n",
    "                try:\n",
    "                    searchStringIndex = searchString.find(match)\n",
    "                except:\n",
    "                    #string does not contain name, bad match\n",
    "                    continueMatch = False\n",
    "                \n",
    "                if continueMatch is True:\n",
    "                    for i in range(len(match)):\n",
    "                        if match[i] == searchString[searchStringIndex]:\n",
    "                            charCount += 1\n",
    "                            searchStringIndex += 1\n",
    "\n",
    "                    #see if searchString matches the entire length of the potential pokemon name\n",
    "                    if ((currBestMatch is None) or ((charCount == len(match)) and (len(match) > len(currBestMatch)))):\n",
    "                        currBestMatch = match\n",
    "            \n",
    "            if currBestMatch is not None: \n",
    "                return currBestMatch\n",
    "            else:\n",
    "                return False\n",
    "        \n",
    "    def getPokemonGeneration(self, pokemonName: string) -> int:\n",
    "        for counter in range(len(self.uniqueDexNames)):\n",
    "            if (pokemonName.lower() == self.uniqueDexNames[counter].lower()):\n",
    "                return int(self.pokemonGenerations[counter])\n",
    "        return False\n",
    "\n",
    "compiledData = DataWrangler()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75ce509d",
   "metadata": {},
   "source": [
    "### Image Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc3b384-e5d2-4a99-8468-f1d0acf74a70",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyseImage(path):\n",
    "    im = Image.open(path)\n",
    "    results = {\n",
    "        'size' : im.size, \n",
    "        'mode' : 'full'}\n",
    "    try:\n",
    "        while True: \n",
    "            if im.tile:\n",
    "                tile = im.tile[0]\n",
    "                update_region = tile[1]\n",
    "                update_region_dimensions = update_region[2:]\n",
    "                if update_region_dimensions != im.size:\n",
    "                    results['mode'] = 'partial'\n",
    "                    break; \n",
    "            im.seek(im.tell() + 1)\n",
    "    except EOFError:\n",
    "        pass\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d44ca95b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#split a given gif into seperate images -- will return paths to all new files\n",
    "def gifToImages(pathToGif: string, destinationPath: string):\n",
    "\n",
    "    #get number of keyframes of gif\n",
    "    if (os.path.isfile(pathToGif)):\n",
    "        createdFilePaths = []\n",
    "        \n",
    "        trans_color = (255, 255, 255)\n",
    "        try:\n",
    "            mode = analyseImage(pathToGif)\n",
    "        except:\n",
    "            print(f\"Failed to check {pathToGif} skipping\")\n",
    "            return []\n",
    "        \n",
    "        try:\n",
    "            with Image.open(pathToGif) as openGif:\n",
    "                numFrames = openGif.n_frames\n",
    "                numToExtract = 0\n",
    "\n",
    "                #check if the number of frames in a given gif is more than the max number defined to get\n",
    "                if numFramesExtractGif != 0 and numFrames > numFramesExtractGif:\n",
    "                    numToExtract = numFramesExtractGif\n",
    "                else:\n",
    "                    numToExtract = numFrames\n",
    "\n",
    "                framesToGet = np.linspace(0, openGif.n_frames - 1, numToExtract)\n",
    "                isFirstFrame = True\n",
    "                palette = openGif.getpalette()\n",
    "\n",
    "                for frameNumber in framesToGet.astype(np.int64):\n",
    "                    # openGif.seek(frameNumber)\n",
    "                    # currFrame = openGif.convert('RGBA')\n",
    "                    # currFrame = Image.alpha_composite(currFrame, img.convert('RGBA'))\n",
    "\n",
    "                    # image = currFrame.convert(\"RGBA\")\n",
    "                    # datas = image.getdata()\n",
    "                    # newData = []\n",
    "\n",
    "    #                     if isFirstFrame:\n",
    "    #                         palette = currFrame.getpalette()\n",
    "    #                         isFirstFrame = False\n",
    "    #                     else:\n",
    "    #                         image.putpalette(palette)\n",
    "\n",
    "                    # for item in datas:\n",
    "                    #     if item[3] == 0: \n",
    "                    #         #transparent\n",
    "                    #         newData.append(trans_color)\n",
    "                    #     else:\n",
    "                    #         newData.append(tuple(item[:3]))\n",
    "\n",
    "                    # image = Image.new(\"RGB\", openGif.size)\n",
    "                    # image.getdata()\n",
    "                    # image.putdata(newData)\n",
    "                    openGif.seek(frameNumber)\n",
    "\n",
    "                    if not openGif.getpalette():\n",
    "                        openGif.putpalette(palette)\n",
    "                \n",
    "                    new_frame = Image.new('RGBA', openGif.size, \"BLACK\")\n",
    "                    \n",
    "                    if mode == 'partial':\n",
    "                        new_frame.paste(last_frame)\n",
    "\n",
    "                    new_frame.paste(openGif, (0,0), openGif.convert('RGBA'))\n",
    "                    new_frame.n_frames = 1\n",
    "                    fileName = f'{extractFileNameFromPath(pathToGif, True)}-{frameNumber}.png'\n",
    "                    finalFullPath = os.path.join(destinationPath, fileName)\n",
    "                    createdFilePaths.append(finalFullPath)\n",
    "                    new_frame.convert('RGB').save(finalFullPath)    \n",
    "        except:\n",
    "            print('err')\n",
    "        return createdFilePaths\n",
    "\n",
    "# gifToImages('./Tmp/abomasnow-mega.gif', generateScrapedPath('./Tmp/abomasnow-mega.gif'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0eb41f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#apply any formatting that is needed for the given image and place into correct directory\n",
    "def processImage(pathToImage: string, isWebPath: bool, overrideDestinationPath: string=None): \n",
    "    destinationPath = None\n",
    "    if overrideDestinationPath is None:\n",
    "        destinationPath = gatherDirectory\n",
    "    else:\n",
    "        destinationPath = overrideDestinationPath\n",
    "\n",
    "    if (len(compiledRE_png.findall(pathToImage)) !=0):\n",
    "        #current image is in the temp directory, copy to other directory\n",
    "\n",
    "        #dont copy if the file is already in the proper compiled directory\n",
    "        if os.path.isdir(destinationPath) is False: \n",
    "            os.mkdir(destinationPath)\n",
    "        try:\n",
    "            with Image.open(pathToImage) as image:\n",
    "                #replace alpha channel with black channel\n",
    "                new_frame = Image.new('RGBA', image.size, \"BLACK\")\n",
    "                new_frame.paste(image, (0,0), image.convert('RGBA'))\n",
    "\n",
    "                fileName = os.path.basename(pathToImage)\n",
    "                finalPath = os.path.join(destinationPath, fileName)\n",
    "                new_frame.convert('RGB').save(finalPath)\n",
    "        except Image.UnidentifiedImageError as imgErr:\n",
    "            print(f\"Unable to ID image {pathToImage}\")\n",
    "\n",
    "            \n",
    "        # shutil.copy2(pathToImage, destinationPath)\n",
    "        #check if image is a gif and convert to a group of images\n",
    "    elif (len(compiledRE_gif.findall(pathToImage)) != 0):\n",
    "        #it is a gif -- if processing image from other dataset (not currently in tmp), shouldnt do extra copy to tmp directory :: TODO: UNLESS EXTRA PROCESSING IS NEEDED (fixing images in some way)\n",
    "        createdGifImages = gifToImages(pathToImage, destinationPath)\n",
    "\n",
    "        #will need to process each image just created\n",
    "        # if createdGifImages is not None:\n",
    "        #     for newImages in createdGifImages:\n",
    "        #         processImage(newImages, False, destinationPath)\n",
    "\n",
    "# processImage('./Datasets/Images/1300-big-front-gifs/001-bulbasaur-s.gif', False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee56d940",
   "metadata": {},
   "source": [
    "### Web Helpers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed136790",
   "metadata": {},
   "outputs": [],
   "source": [
    "def downloadImage(imageURL: string):\n",
    "\n",
    "    #create filename for new file - get file name from URL along with parent directory on remote server (combine)\n",
    "    nameBeginIndex = imageURL.rfind('/')\n",
    "    pathWithoutName = imageURL[:nameBeginIndex]\n",
    "    extendedDirIndex = pathWithoutName.rfind('/')\n",
    "    fileName = pathWithoutName[extendedDirIndex+1:] + '--' + imageURL[nameBeginIndex+1:]\n",
    "\n",
    "    fullNewFilePath = os.path.join(tempDirectory, fileName)\n",
    "\n",
    "    if (os.path.isfile(fullNewFilePath) is not True):\n",
    "        #download the file from the remote and place in new path\n",
    "        read = requests.get(imageURL)\n",
    "\n",
    "        with open (fullNewFilePath, 'wb') as f: \n",
    "            f.write(read.content)\n",
    "            f.close()\n",
    "            \n",
    "# downloadImage('https://play.pokemonshowdown.com/sprites/ani-back/ferroseed.gif')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f288c3",
   "metadata": {},
   "source": [
    "### Supporting methods for image search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c806a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recursively search through a provided URL to find gifs\n",
    "def browseForImages(currRoot):\n",
    "    global listOfImageURLs\n",
    "    \n",
    "    #avoid april fools day images on pokemon showdown\n",
    "    if \"afd\" not in currRoot:\n",
    "        page = requests.get(currRoot)\n",
    "        soup = BeautifulSoup(page.content, \"html.parser\")\n",
    "\n",
    "        results = soup.find_all(\"a\", text=compiledRE_forwardSlash)\n",
    "        pngSources = soup.find_all(\"a\", text=compiledRE_png)\n",
    "        gifSources = soup.find_all(\"a\", text=compiledRE_gif)\n",
    "\n",
    "        for image in pngSources: \n",
    "            full = currRoot + image.text\n",
    "            listOfImageURLs.append(full)\n",
    "\n",
    "        for image in gifSources: \n",
    "            full = currRoot + image.text\n",
    "            listOfImageURLs.append(full)\n",
    "\n",
    "        #navigate through all of the possible directories \n",
    "        for each in results: \n",
    "            subURL = currRoot + each.text\n",
    "            browseForImages(subURL)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "860cf1d7",
   "metadata": {},
   "source": [
    "## Gather data from internet resources"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2308d23",
   "metadata": {},
   "source": [
    "#### Gather image paths into list and then download images as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f56a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "if gatherFromWeb is True:\n",
    "    #gather target URLs for images\n",
    "    for target in TARGETURLS:\n",
    "        browseForImages(target)\n",
    "\n",
    "    #go through and download images as needed\n",
    "    for url in listOfImageURLs: \n",
    "        downloadImage(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff175689",
   "metadata": {},
   "source": [
    "Took 130 minutes to complete"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b906b685",
   "metadata": {},
   "source": [
    "## Sort data gathered into useable dataset for testing and training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c6549d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def searchForFiles(currentDir):\n",
    "    if os.path.isdir(currentDir):\n",
    "        nextLevelContents = os.listdir(currentDir)\n",
    "        for content in nextLevelContents:\n",
    "                #go through all contents except for gathered directory \n",
    "                fullPath = os.path.join(currentDir, content)    \n",
    "                searchForFiles(fullPath)   \n",
    "    else:\n",
    "        #this child has to be a file -- copy to core dataset \n",
    "        pokemonName = compiledData.getProperPokemonName(currentDir)\n",
    "        if pokemonName is not False and compiledData.getPokemonGeneration(pokemonName) in generationsToPrepare:\n",
    "            datasetPath = os.path.join(gatherDirectory, pokemonName)\n",
    "            if os.path.isdir(datasetPath) is False:\n",
    "                os.mkdir(datasetPath)\n",
    "            processImage(currentDir, False, datasetPath)\n",
    "\n",
    "if PROCESS_TEMP_IMAGES is True:\n",
    "    searchForFiles(tempDirectory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fdf5b77-dead-4f5e-8849-057950d229ab",
   "metadata": {},
   "source": [
    "## Verifiy Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d296ed3-43d8-468b-a84c-4d99f729b984",
   "metadata": {},
   "source": [
    "## Test Images to ensure proper format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25711995-3747-4487-abb4-23ff2148aa52",
   "metadata": {},
   "outputs": [],
   "source": [
    "def testFile(filePath, printErrors=True) -> bool:\n",
    "    if os.path.getsize(filePath) == 0 or os.path.isdir(filePath):\n",
    "        if printErrors:\n",
    "            print(filePath + \" is zero length or is directory, ignoring\")\n",
    "        return False\n",
    "    elif \"afd\" in filePath:\n",
    "        if printErrors:\n",
    "            print(filePath + \" this is garbage file, removing\")\n",
    "        return False\n",
    "    elif \"digimon\" in filePath:\n",
    "        if printErrors:\n",
    "            print(f\"{filePath} is a digimon, ignoring\")\n",
    "        return False\n",
    "    elif \"meganium\" not in filePath and \"yanmega\" not in filePath:\n",
    "        if INCLUDE_ALT_FORMS is False and (\"mega\" in filePath or \"gigantamax\" in filePath or \"gmax\" in filePath): \n",
    "            if printErrors:\n",
    "                print(f\"{filePath} is alt form, ignoring\")\n",
    "            return False\n",
    "    else:\n",
    "        #attempt to open file to confirm that it is a valid file\n",
    "        tmp = Image.open(filePath)\n",
    "        tmp.load()\n",
    "        if tmp.format != 'PNG':\n",
    "            if printErrors:\n",
    "                print(file + \" is not correct format, ignoring\")\n",
    "            return False\n",
    "        if tmp.n_frames > 1:\n",
    "            if printErrors:\n",
    "                print(file + \"too many frames, ignoring\")\n",
    "        tmp.close()\n",
    "\n",
    "        #ensure all images are encoded in the correct format \n",
    "        with open(filePath, 'rb') as imageFile:\n",
    "            if imageFile.read().startswith(b'RIFF'):\n",
    "                if printErrors:\n",
    "                    print(file + \" isnt right type, ignoring\")\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "# testFile('../Datasets/Main/Images/Train/gyarados/pokemon--gyarados.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30acee7d-bc93-450c-8541-4b904d39c5a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # listOfPokemonDirs = os.listdir('../Datasets/Main/Images/Train/')\n",
    "# listOfAllImages = list(paths.list_images(gatherDirectory))\n",
    "# verifiedFiles = []\n",
    "\n",
    "# for file in listOfAllImages: \n",
    "#     pokemonName =  compiledData.getProperPokemonName(file)\n",
    "#     gen = compiledData.getPokemonGeneration(pokemonName)\n",
    "#     if gen in generationsToPrepare: \n",
    "#         if testFile(file) is True: \n",
    "#             verifiedFiles.append(file)\n",
    "\n",
    "# #copy verified files to core model directory\n",
    "# for file in verifiedFiles: \n",
    "#     pokemonName = compiledData.getProperPokemonName(file)\n",
    "#     finalPokemonDir = os.path.join(DIR_MODE_IMAGES, pokemonName)\n",
    "#     if os.path.isdir(finalPokemonDir) is False: \n",
    "#         os.mkdir(finalPokemonDir)\n",
    "#     shutil.copy2(file, finalPokemonDir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35fd8a5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if PROCESS_TEMP_IMAGES is True:\n",
    "    listOfPokemonDirs = os.listdir(gatherDirectory)\n",
    "    for pokemonDir in listOfPokemonDirs:\n",
    "        #check if the pokemon is in the generation of targeted pokemon \n",
    "        pokemonName = compiledData.getProperPokemonName(pokemonDir)\n",
    "        gen = compiledData.getPokemonGeneration(pokemonName)\n",
    "        if gen in generationsToPrepare:\n",
    "\n",
    "\n",
    "            #decide if to copy image, then copy if so \n",
    "            pathPokemonDir = os.path.join(gatherDirectory, pokemonDir)\n",
    "            # pathPokemonDir = os.path.join(pokemonDir, \n",
    "            # fileList = os.listdir('../Datasets/Main/Images/Train/gyarados')|\n",
    "            fileList = os.listdir(pathPokemonDir)\n",
    "            verifiedList = []\n",
    "            \n",
    "            for file in fileList: \n",
    "                fullPath = os.path.join(pathPokemonDir, file)\n",
    "                # fullPath = os.path.join('../Datasets/Main/Images/Train/gyarados', file)\n",
    "                if testFile(fullPath) is True:\n",
    "                    verifiedList.append(file)\n",
    "\n",
    "            for file in fileList:\n",
    "                finalPokemonDir = os.path.join(DIR_MODEL_IMAGES, pokemonName)\n",
    "                currPath = os.path.join(pathPokemonDir, file)\n",
    "                if os.path.isdir(finalPokemonDir) is False: \n",
    "                    os.mkdir(finalPokemonDir)\n",
    "                shutil.copy2(currPath, os.path.join(finalPokemonDir, file))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f79f5a1f-6be7-4ed7-905b-b22760247f90",
   "metadata": {},
   "source": [
    "## Data For Model Verification and Testing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81667e4",
   "metadata": {},
   "source": [
    "### Prepare Test DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2766366a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prepareTestDS = True \n",
    "testDS = \"./testImages\"\n",
    "if PREPARE_TEST_DS is True: \n",
    "    listOfDirs = os.listdir(DIR_MODEL_IMAGES)\n",
    "    if os.path.isdir(testDS) is False: \n",
    "        os.mkdir(testDS)\n",
    "    dirCounter = 0\n",
    "    for dir in listOfDirs: \n",
    "        counter = 0 \n",
    "        done = False \n",
    "        seed = 32\n",
    "        imageDir = os.path.join(DIR_MODEL_IMAGES, dir)\n",
    "        images = os.listdir(imageDir)\n",
    "        random.seed(seed)\n",
    "        random.shuffle(images)\n",
    "        while done is False:\n",
    "            print(counter)\n",
    "            sourcePath = os.path.join(imageDir, images[counter])\n",
    "            destinationPath = os.path.join(testDS, images[counter])\n",
    "            if (testFile(sourcePath, False)):\n",
    "                shutil.copy2(sourcePath, destinationPath)\n",
    "                done = True\n",
    "            else:\n",
    "                counter += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e4e02a",
   "metadata": {},
   "source": [
    "### Main Dataset Stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0252a31",
   "metadata": {},
   "source": [
    "<!-- os.path.listdir -->"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "831b1e12b54c1ff73ac9f45e5c09cfbb42209f7870334bf75877d041a50f3928"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
